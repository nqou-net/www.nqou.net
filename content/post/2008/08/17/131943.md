---
date: 2008-08-17T13:19:43+09:00
draft: false
iso8601: 2008-08-17T13:19:43+09:00
tags:
  - perl
title: mt-search.cgiの負荷に対するrobots.txtの効果

---
前々からサーバに対する負荷が気になっていた。 movabletype自体の負荷だと思っていたのだが、実際にはある特定のファイルが原因ということが調べていく過程でわかった。

> Movable Typeの検索機能を担うmt-search.cgiですが、これがまた激しく検索が遅くて重い。サーバーにもかなりの負荷が掛かってる模様。サーバーやさんに申し訳ないのでmt-search.cgiを止めることにしました。

\[[mt-search.cgiを削除した (KUMA TYPE)](http://blog.kumacchi.com/2008/07/mtsearchcgi.html)]

ようするに、mt-search.cgiが激重ということなんですね。

> このブログで使っているMovable Typeのサーチ機能を提供するのがmt-search.cgi。単にPerlのパターン・マッチングを使っているだけなんで、非常～に低速で重たいサーチ機能なんですよ。いくらうちの環境が「どん亀」とはいえ、CPUパワーの9割以上を持っていかれますヽ(;´д｀)ノ

\[SPV = Nightmare: Google様がmt-search.cgiを狙い討ちなんですけど]

「mt-search」で調べると「[mt-search.cgiを捨てて簡単メタサーチにしてみよう - Ogawa::Memoranda](http://blog.as-is.net/2004/11/mt-searchcgi.html)」とか「[mt-search.cgiの代替プログラム。 (Junnama Online (Mirror))](http://junnama.alfasado.net/online/2007/01/mtsearchcgi.html)」というように、プログラム自体を変更するという話題が多いです。 もちろん、プログラム自体の負荷を軽くしてやるのも効果はあるわけですが、アクセスログとかを追っていくと、結局のところ、人間様じゃなくロボットが大量に収集していくのが問題なんですね。 ロボットに収集をやめさせるほうが効果が高いのではないかと思ってやってみました。

検索ロボットに指示するには「robots.txt」を使います。 昔はあまり意味が無かったようですが、最近は大手のロボットは解釈するようになったらしいです。

> ASY!Yahoo,Google,Microsoft(Live Search)の3社は、自身の運用するクローラーがRobots.txtを承認するという取り決めを行っています。これによりrobots.txtの信用力は格別のものとなり、安心して使えるようになりました。（参考サイトYahoo Search Blog）

\[[robots.txtの正確な書式,ロボット対策,noindex,nofollow | ASY! - エイジー](http://dokodemo.rankuappu.com/syono5.html)]

なので、その効果を体感するためにも、「robots.txt」での対応をしてみました。 

とりあえず、[過去のブログ](/)に対してはプログラムが入っているディレクトリへのアクセスを禁止しました。 

[http://blog.nqou.net/robots.txt](/robots.txt) 

その結果、対策前のある一日のxreaでいう負荷ポイントが557だったのが、ここ最近は0から86になっていました。 同じ日の「mt-search.cgi」へのアクセス数は284でしたが、少し負荷のあったこの前の木曜日のアクセス数は10未満でした。 mt-search.cgiを置き換えるまでも無く、十分に効果を得ることができました。
